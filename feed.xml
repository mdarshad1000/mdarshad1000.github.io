<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://mdarshad1000.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://mdarshad1000.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-16T16:24:25+00:00</updated><id>https://mdarshad1000.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Tagging Document - LangChain</title><link href="https://mdarshad1000.github.io/blog/2023/doctagging/" rel="alternate" type="text/html" title="Tagging Document - LangChain"/><published>2023-08-10T09:01:00+00:00</published><updated>2023-08-10T09:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2023/doctagging</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2023/doctagging/"><![CDATA[<h3 id="tagging-document---langchain-">Tagging Document - LangChain 🦜</h3> <p><code class="language-plaintext highlighter-rouge">Labelling/Classifying corpus using LangChain</code></p> <p>Recently LangChain introduced Document Tagging Chain. Tagging refers to simply assigning label(s) to a corpus. I will cover a basic demo of how document tagging works using LangChain. From analyzing sentiment in customer feedback to identifying the intensity oflanguage use, the potential applications of this technology are vast.</p> <p>I will take the text-book task for classification in Machine Learning i.e Email Classification to demonstrate tagging via langchain. We already have a plethora of tools in the market for classifying and filtering out emails. So how will using a Tagging chain from LangChain will be any different/better?</p> <p>Unfortunately, these tools are based on rule-based filtering and classification techniques, which may not capture the context and nuances of emails effectively. This is where we can power up the classification using tagging chain.</p> <ul> <li>Install the dependencies</li> </ul> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span>pip <span class="nb">install</span> <span class="nt">-qU</span> langchain pydantic
</code></pre></div></div> <ul> <li>Importing dependencies</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span><span class="p">,</span> <span class="n">create_tagging_chain_pydantic</span>
<span class="kn">from</span> <span class="n">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="n">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="n">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Fieldimport</span> 
<span class="kn">import</span> <span class="n">os</span>
</code></pre></div></div> <ul> <li>Prepare the source text</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_source</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
Subject: Urgent Concerns about the Reliability of WonderTech AI Product

Dear Arshad,

I am Bruce, the CTO at Microsoft. I am writing to express my deep disappointment regarding the recent issues with our AI product.

We value our longstanding partnership, and it is crucial that we address these concerns promptly. Please provide a comprehensive plan outlining the steps you will take to improve the reliability of our AI system.

I appreciate your partnership and trust that, by working together, we can overcome these challenges.

Sincerely,
Bruce
CTO
Microsoft

</span><span class="sh">"""</span>
</code></pre></div></div> <ul> <li>Create Tag description by Pydantic class</li> </ul> <p>I outlined four specific tags that provide a detailed description of the topic. These tags also include information about the sender’s significance, the urgency of their message, and their feelings. These details assist the recipient in better organizing their emails for efficient management.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">EmailFeatures</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span>
        <span class="bp">...</span>
        <span class="n">enum</span><span class="o">=</span><span class="p">[</span>
            <span class="sh">"</span><span class="s">Customer Complaint</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Follow-up</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Proposal</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Demo/Product Presentation</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Deal Negotiation</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Order Processing</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Customer Testimonials/Reviews</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Product Information Request</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Account Support</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Shipping and Delivery</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Payment and Billing</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Return and Refund</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Product Support</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Technical Support</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Partnership/Cooperation</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Event/Conference Invitation</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Webinar/Training Registration</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Other</span><span class="sh">"</span>
        <span class="p">],</span>
    <span class="p">)</span>

    <span class="n">sender_weighs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span>
        <span class="p">...,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">The importance of sender based on their title and company, and their content of the message</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">urgent</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span>
        <span class="p">...,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">Score 1-10, 10 is the highest level of urgency</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">sentiment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span>
        <span class="p">...,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">wether the email has a negative, positive or neutral sentiment</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></div> <ul> <li>setting up model and chain</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">"</span><span class="s">OPENAI_API_KEY</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">your_api_key</span><span class="o">&gt;</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-3.5-turbo-16k</span><span class="sh">"</span><span class="p">)</span>
<span class="n">tagging_chain</span> <span class="o">=</span> <span class="nf">create_tagging_chain_pydantic</span><span class="p">(</span><span class="n">EmailFeatures</span><span class="p">,</span> <span class="n">llm</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">tagging_chain</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">text_input</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div></div> <p>The output would be:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>topic='Customer Complaint', sender_weighs=10, urgent=10, sentiment='negative'
</code></pre></div></div> <p>These tags would give a clearer picture of the email to you without you having to read through the entire mail.</p> <p>Lastly, there are many other potential use cases such as:</p> <ul> <li>Resume Screening</li> <li>Medical Record Analaysis</li> <li>Legal Document Analysis</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Labelling/Classifying corpus using LangChain]]></summary></entry><entry><title type="html">LangChain vs (and?) LlamaIndex 🦜🦙</title><link href="https://mdarshad1000.github.io/blog/2023/llamindexvlangchain/" rel="alternate" type="text/html" title="LangChain vs (and?) LlamaIndex 🦜🦙"/><published>2023-07-28T19:01:00+00:00</published><updated>2023-07-28T19:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2023/llamindexvlangchain</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2023/llamindexvlangchain/"><![CDATA[<h2 id="langchain--vs-and-llamaindex-">LangChain 🦜 vs (and?) LlamaIndex 🦙</h2> <p><code class="language-plaintext highlighter-rouge">The Key Differences</code></p> <blockquote> <p>Disclaimer: This is more of an opinionated piece than fact-based</p> </blockquote> <p>LlamaIndex and LangChain have been arguably the two most popular and successful frameworks in the LLM space. In the short span of few months, both the frameworks have taken the developer community by aplomb. What NumPy and Pandas did for machine learning, LangChain and LlamaIndex have done for LLMs, greatly increasing their usability and functionality. From a distance, both frameworks seem to primarily do the same thing, however that’s not ture.</p> <h4 id="llamaindex--swift-search-and-retrieval">LlamaIndex 🦙: Swift Search and Retrieval</h4> <p>Imagine you’re building an app, and you need it to find stuff in a bunch of documents fast. That’s where LlamaIndex comes in handy. It’s like your trusty librarian, organizing your documents and helping you find what you want without any fuss. Perfect for tasks like summarizing articles, answering questions from texts, or digging up specific info in a pile of words.</p> <p>Strengths:</p> <ul> <li>Easy Search: LlamaIndex is ace at searching through documents.</li> <li>Quick Retrieval: It’s lightning-fast at getting you the info you need.</li> <li>Simple and Straightforward: No rocket science here; it’s easy to use for basic searches.</li> </ul> <p>Weaknesses:</p> <ul> <li>Not for Super Complex Jobs: While it’s great for searching, it’s not the best for really tricky tasks.</li> <li>Less Versatile: It’s a search whiz, but not a jack-of-all-trades like some other tools.</li> </ul> <p>Use Cases:</p> <ul> <li>Finding Specific Info: If your project is all about unearthing things in documents, LlamaIndex has your back.</li> </ul> <h4 id="langchain-">Langchain 🦜:</h4> <p>Now, let’s say you’re shooting for more than just finding things. You want your app to be a versatile superstar, chatting with users, acting as a virtual assistant, or getting creative with language. That’s where Langchain steps in. It’s like a toolbox with a bunch of gadgets for all sorts of language magic. It’s your go-to if you’re building something like a chatty bot or a really fancy AI sidekick.</p> <p>Strengths:</p> <ul> <li>Master of Many: Langchain can handle all sorts of language-powered tasks, from chatting to creating.</li> <li>Flexible as a Rubber Band: You can twist and turn it to fit different project needs.</li> <li>Advanced Features: It’s got the cool stuff for those “wow” moments.</li> </ul> <p>Weaknesses:</p> <ul> <li>Not the Best Searcher: While it’s a multi-talented tool, searching isn’t its strong suit, unlike LlamaIndex.</li> <li>Takes a Bit More Setup: Since it’s so versatile, it might need a tad more time to set up for your needs.</li> </ul> <p>Use Cases:</p> <ul> <li>Chatty Apps and Assistants: If you’re thinking of building a chatbot or a super-smart assistant, Langchain is your hero.</li> </ul> <p>Choosing the Right One:</p> <p>So, which one should you pick? It’s a bit like choosing a tool from your toolbox. If you need to quickly fish out info from documents, LlamaIndex is your buddy. But if you’re after a dynamic, all-in-one language wizard, Langchain is the way to roll.</p> <p>Remember, the best choice depends on the superpowers your project needs.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[How are they different?]]></summary></entry><entry><title type="html">Transformers</title><link href="https://mdarshad1000.github.io/blog/2023/transformers/" rel="alternate" type="text/html" title="Transformers"/><published>2023-03-15T09:01:00+00:00</published><updated>2023-03-15T09:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2023/transformers</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2023/transformers/"><![CDATA[<h3 id="transformers">Transformers</h3> <p><code class="language-plaintext highlighter-rouge">What are Transformers?</code></p> <p>Transformers are a type of neural network architecture that was introduced in the paper “Attention is All You Need” by Vaswani et al. in 2017. Since then, it has become one of the most popular and successful models in natural language processing (NLP) tasks such as language translation, summarization, and text classification. Furthermore it is the foundation for Language Models and their application.</p> <p>The key innovation of the Transformer architecture is the use of attention mechanisms. In a traditional neural network, each input is processed independently, without any information about the relationships between the inputs. In contrast, the Transformer model uses attention mechanisms to weight the inputs based on their relevance to the output.</p> <p>For example, in a language translation task, the Transformer model might pay more attention to the words at the beginning and end of a sentence, as these are typically more important for determining the overall meaning of the sentence. On the other hand, it might pay less attention to words that are less important or less relevant to the translation.</p> <p>Another key advantage of the Transformer architecture is its ability to process input sequences in parallel. Traditional recurrent neural networks (RNNs), which are commonly used in NLP tasks, process input sequences one element at a time, making them slow and inefficient. In contrast, the Transformer model processes all elements of the input sequence at the same time, allowing it to run much faster and more efficiently.</p> <p>Attention At a high level, the Transformer model is based on the idea of self-attention, which allows the model to weight the input elements based on their relevance to the output. Mathematically, self-attention can be computed using the following formula.</p> <h4><i>$$Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V$$</i></h4> <p>Here, \(Q\),\(K\), and \(V\) are matrices of query, key, and value vectors, respectively. \(d_ k\)​ is the dimensionality of the key vectors. The dot product of \(Q\) and \(K^T\) is divided by the square root of \(d_k\)​ to ensure that the dot products do not become too large and blow up the softmax function. The output of the self-attention layer is a weighted sum of the value vectors, with the weights determined by the dot products of the query and key vectors. In addition to self-attention, the Transformer model also includes feed-forward layers and residual connections. The feed-forward layers consist of a linear transformation followed by a non-linear activation function, such as ReLU. The output of the feed-forward layers is then added to the output of the self-attention layers using residual connections.</p> <p>Overall, the Transformer model can be described using the following pseudo-code:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">each</span> <span class="nb">input</span> <span class="n">sequence</span><span class="p">:</span>
<span class="n">encode</span> <span class="nb">input</span> <span class="n">sequence</span> <span class="n">using</span> <span class="n">self</span><span class="o">-</span><span class="n">attention</span> <span class="ow">and</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">layers</span>
<span class="n">add</span> <span class="n">the</span> <span class="n">output</span> <span class="n">to</span> <span class="n">the</span> <span class="n">original</span> <span class="nb">input</span> <span class="n">using</span> <span class="n">residual</span> <span class="n">connections</span>
<span class="nb">apply</span> <span class="n">layer</span> <span class="n">normalization</span>

<span class="nb">apply</span> <span class="n">final</span> <span class="n">self</span><span class="o">-</span><span class="n">attention</span> <span class="ow">and</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">layers</span> <span class="n">to</span> <span class="n">obtain</span> <span class="n">output</span>

</code></pre></div></div> <h2>How to set up a Transformer Model?</h2> <p>Here is an example of how you can set up a Transformer model in Python using the <code class="language-plaintext highlighter-rouge">Transformers</code> library:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">transformers</span>

<span class="c1"># Set up the Transformer model and tokenizer
</span><span class="n">model_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">bert-base-cased</span><span class="sh">'</span> <span class="c1"># choose a pre-trained model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="p">.</span><span class="n">BertModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="p">.</span><span class="n">BertTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># Tokenize input text
</span><span class="n">text</span> <span class="o">=</span> <span class="sh">"</span><span class="s">This is some input text that I want to feed into the Transformer model.</span><span class="sh">"</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">'</span><span class="s">pt</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># convert text to numerical input
</span>
<span class="c1"># Run input through the model
</span><span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</code></pre></div></div> <p>This code sets up a BertModel from the Transformers library, which is a type of Transformer model developed by Google. It also sets up a BertTokenizer, which is used to convert the input text into a numerical representation that can be fed into the model.</p> <p>Finally, the code tokenizes the input text and passes it through the model to obtain the output. The output of the model will be a tensor containing the encoded representation of the input text.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[What are Transformers?]]></summary></entry><entry><title type="html">ChatGPT</title><link href="https://mdarshad1000.github.io/blog/2023/chatgpt/" rel="alternate" type="text/html" title="ChatGPT"/><published>2023-01-15T09:01:00+00:00</published><updated>2023-01-15T09:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2023/chatgpt</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2023/chatgpt/"><![CDATA[<h3 id="chatgpt">ChatGPT</h3> <p><code class="language-plaintext highlighter-rouge">The subtle art of ChatGPT failure</code></p> <p>Is it an AGI? Is it SkyNet? No, it is a large language model. ChatGPT is a language model, optimised for dialogue and (for the first time?) equipped with a minimal, beautiful and responsive interface for interaction. There are warnings as soon as you start using it - it is in early stages, it can make mistakes, and it is NOT a lookup on the web(and yes it will not replace Google, at least not right now).  I put it to a very specific task - to help me write the K-Nearest neighbours algorithm in PyTorch. It came to me because I had been thinking of putting myself to this task for a while. One of my friends had it as an interview question! So, here I was asking a Language model probably trained in PyTorch to give me PyTorch code for a simple KNN algorithm. It did not disappoint. It gave me a very neat looking code snippet, with very clear comments and the entire end to end algorithm - right from creating dummy synthetic data to finding the distances cleanly and then getting the predictions. I was very impressed! </p> <p>I started going through it in detail and there it lay. Very subtle. Extremely minute yet a very significant error. While inference, in order to find the top k nearest neighbours from the computed distances, GPT3 used the frequently employed topK PyTorch function. However, it did not set the argument to find the topK smallest numbers, instead it went by the default parameters which ended up fetching the topK largest distances! And voila, the final predictions were wrong. </p> <p>There is no way one would see this unless they are really looking into it. And that’s the problem - Trust. You can not trust the outputs from chat GPT to be the absolute truth. If someone were to have uploaded this answer on Stack Overflow, they would have had 10 downvotes, 3 comments, and a large case of imposter syndrome within the turn of the hour - and that is why humans probably still have the edge over trillions of weight parameters. TLDR-tread lightly with chat GPT if the output is even remotely significant to you! Or else, just play around and have fun!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The subtle art of ChatGPT failure]]></summary></entry><entry><title type="html">Navigating the Data Jungle</title><link href="https://mdarshad1000.github.io/blog/2023/datasheet/" rel="alternate" type="text/html" title="Navigating the Data Jungle"/><published>2023-01-02T09:01:00+00:00</published><updated>2023-01-02T09:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2023/datasheet</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2023/datasheet/"><![CDATA[<h3 id="navigating-the-data-jungle">Navigating the Data Jungle</h3> <p><code class="language-plaintext highlighter-rouge">A Review of Datasheets of Datasets</code></p> <p><br/> In our rapidly evolving digital world, where data is at the core of innovation and exploration, the quality and dependability of datasets stand as fundamental. Today, we embark on a journey to delve into a pivotal research paper titled “Datasheets for Datasets.” This paper has sparked enthusiasm among data enthusiasts, researchers, and machine learning practitioners, offering a pathway to a more transparent, responsible, and ethical era in data utilization. Although the paper was published back in 2018, its relevance and impact still prevail.</p> <blockquote> <p>Access the paper <a href="https://arxiv.org/abs/1803.09010">here</a>.</p> </blockquote> <h4 id="1-contributions">1. Contributions</h4> <p>The manuscript furnishes pioneering insight into the domain of machine learning by proposing a novel approach to dataset documentation. The authors recommend using datasheets to offer information on a dataset such as its motivation, composition, and collection process. This practice would permit users to access crucial data with ease, negating the need to sift through bulky documents or contact the author directly. The study explores the potential of adopting this methodology to encourage better communication between dataset creators and consumers, promoting greater transparency within the machine learning community.</p> <p><br/></p> <h4 id="2-strengths">2. Strengths</h4> <p>The proposed approach in this paper has several notable strengths. Firstly, it offers a robust framework for dataset creators to communicate effectively with consumers, promoting a better understanding of the dataset and its potential uses. Datasheets facilitate this, which provide easy access to crucial information without the need to go through long documents or reach out to the creator. Datasheets promote transparency within the machine learning community by clarifying the nuances of data collection and intended purposes. By providing insight into data collection and intended uses, datasheets encourage accountability and transparency in high-stakes domains where data accuracy is crucial. Additionally, datasheets serve as an essential tool for identifying and mitigating potential risks or drawbacks associated with datasets.</p> <p><br/></p> <h4 id="3-weaknesses">3. Weaknesses</h4> <p>Despite its promise, the proposed approach in this paper does have limitations that must be acknowledged. First, it could be arduous to ensure that all datasets are accompanied by a datasheet, as it demands additional exertion from dataset creators. This necessitates modifying organizational infrastructure and workflows to support this additional workload. There can also be instances where the creator doesn’t have the expertise and resources. Datasheets can become outdated rapidly if not regularly updated with new information, and there is no guarantee that consumers will read and comprehend the contents of a datasheet before utilizing or relying on data from it. Ultimately, creating a datasheet will always require a time investment, so proper incentives must be put in place to justify the expenditure. Overall, while the proposed approach has its strengths, it is essential to address its weaknesses to ensure its successful adoption and implementation in the machine learning community.</p> <p><br/></p> <h4 id="4-future-directions">4. Future directions</h4> <p>To extend the work done there are several potential avenues, we can start by creating a sample datasheet for an existing popular dataset as it would give a better understanding and direction to the dataset creators. We can work on developing standards and best practices for datasheet creation and provide recommendations on what works best in different contexts. The authors of the paper claim that datasheets can improve the communication between dataset creators and consumers significantly, but it is still unclear about the effectiveness of datasheets in achieving this goal. Therefore we can conduct a study to explore to evaluate the efficacy of datasheets. As discussed earlier concerning the difficulties in the creation of datasheets, we can also explore the potential of automated tools in generating datasheets based on metadata and other information about a dataset.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A Review of 'Datasheets for Datasets']]></summary></entry><entry><title type="html">LangChain 🦜</title><link href="https://mdarshad1000.github.io/blog/2022/langchain/" rel="alternate" type="text/html" title="LangChain 🦜"/><published>2022-12-12T09:01:00+00:00</published><updated>2022-12-12T09:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2022/langchain</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2022/langchain/"><![CDATA[<h2 id="langchain-">LangChain 🦜</h2> <p><code class="language-plaintext highlighter-rouge">The Next Big Thing in the LLM Wave?</code></p> <p><br/> While on Twitter, I came across this groundbreaking framework called LangChain, developed by Harrison Chase. While ChatGPT is getting all the attention, LangChain isn’t receiving the recognition it truly deserves from the ML community.</p> <h4 id="what-is-langchain">What is LangChain?</h4> <p>LangChain is a library that assists developers in building applications powered by large language models (LLMs). It accomplishes this by providing a framework for connecting LLMs to other sources of data, such as the internet or your personal files. This enables developers to chain together multiple commands to create more complex applications.</p> <h4 id="why-is-it-important">Why is it Important?</h4> <p>There are several reasons why developers should take notice of this framework. Firstly, it simplifies the process of building applications that utilize LLMs. It abstracts many complexities and provides simple classes and functions that can be chained together, allowing us to connect with external data sources.</p> <ul> <li><b>Flexibility:</b> LangChain is designed to be flexible and extensible, enabling easy component swapping and chain customization to meet specific needs.</li> <li><b>Speed:</b> The LangChain team continually works on improving the library’s speed, ensuring users have access to the latest LLM features.</li> <li><b>Community:</b> LangChain boasts a growing and active community.</li> </ul> <h4 id="use-cases">Use Cases</h4> <p>Fine-tuning a large language model can be somewhat daunting, and even if you find it easy, achieving the desired output can be challenging. Often, fine-tuning isn’t necessary for small to medium-scale projects. This leaves us with the option of using prompts. While this approach can work, it presents multiple challenges when you begin to increase the complexity of the LLM applications you’re building. This is where LangChain will be THE framework to use.</p> <p>Some potential use cases:</p> <ul> <li>Chatbots</li> <li>Summarization</li> <li>Bypassign the context window of LLMs</li> <li>Building Personalized Assistants</li> </ul> <p>Despite early days, this python library is packed with incredible features for building amazing tools around the core of LLMs. LangChain is the key to unleash the unexplored potential of LLMs.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The Next Big Thing?]]></summary></entry><entry><title type="html">Augmented Reality</title><link href="https://mdarshad1000.github.io/blog/2022/ar/" rel="alternate" type="text/html" title="Augmented Reality"/><published>2022-05-15T21:01:00+00:00</published><updated>2022-05-15T21:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2022/ar</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2022/ar/"><![CDATA[<h2 id="augmented-reality">Augmented Reality</h2> <p><code class="language-plaintext highlighter-rouge">The Rise of Technology</code></p> <blockquote> <p>Augmented reality can enhance our perception of reality and make the invisible visible.</p> </blockquote> <p><i>-Helen Papagiannis, author of “Augmented Human”</i></p> <h3 id="introduction">Introduction</h3> <p>Let’s unpack the mind-blowing technology that is revolutionizing the present and the future i.e Augmented Reality. Augmented Reality (AR) is a subset of a rather broader spectrum, which is Immersive technology. Immersive Technology comprising of augmented reality, virtual reality, and mixed reality are amongst the fastest growing and most fascinating technologies in the modern-day. To put it in a nutshell immersive technologies create or extend reality and this is done by immersing the user in a digital environment.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/AR-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/AR-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/AR-1400.webp"/> <img src="/assets/img/AR.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="what-is-augmented-reality">What is Augmented Reality?</h3> <p>Theoretically, Augmented Reality projects computer generated augmentation on top of reality helping us perform tasks better and efficiently. Augmented reality, which falls in between reality and virtual reality, is a method used to render real-world data and present it intuitively so that virtual elements resemble the present reality to an extent. But the revolution doesn’t stop here. Have you ever tried to catch a Pokémon using Pokémon Go or made a video of your bitmoji dancing on the top of your table on Snapchat? AR. makes these possible.</p> <blockquote> <p><i>In layman terms, if we give a deep thought about our existence, we will realise that our body and mind exist in a mix of space and time, which we perceive as “Reality”. Moreover, nowadays we have an option to exist in a digital/virtual environment that is a mix of computer-generated space and time, which we call Virtual Reality. Between these two extremes, various other types of reality exist which is a result of the interweaving of Reality and Virtual Reality to varying degrees. It can be concluded that Augmented Reality as a concept implies Reality with a certain amount of Virtual Reality added for extra flavour, but not so much as to overwhelm it, as our main motive is to bring the virtual elements to the physical world and not the other way around</i></p> </blockquote> <h3 id="a-brief-history-of-augmented-reality">A brief history of Augmented Reality</h3> <p>You might think AR is a new technology; well, on the contrary, it has been around for numerous decades. Augmented reality was first achieved, to some extent, by a cinematographer called Morton Heilig in 1957. He invented the Sensorama, which delivered visuals, sounds, vibrations, and smells to the viewer. Of course, it wasn’t computer-controlled but it was the first example of an attempt at adding additional data to an experience.</p> <p>Then in 1968, Ivan Sutherland developed the first ever AR gadget called The Sword of Damocles, this system used computer graphics to show users simple wireframe drawings.</p> <p>The first properly functioning AR system was probably the one developed at USAF Armstrong’s Research Lab by Louis Rosenberg in 1992. This was called Virtual Fixtures and was an incredibly complex robotic system, which was designed to compensate for the lack of high-speed 3D graphics processing power in the early 90s. It enabled the overlay of sensory information on a workspace to improve human productivity</p> <p>From the onset, people are constantly working to improve and further develop this promising technology and there were many breakthroughs in augmented reality since the earliest attempts.</p> <h3 id="the-current-state-of-play-in-augmented-reality">The Current State of Play in Augmented Reality</h3> <p>In recent years, the rapid development of augmented reality technology has aroused people’s high attention. Augmented reality is achieved through a variety of technological innovations; these can be implemented on their own or in conjunction with each other to create augmented reality. They include:</p> <ul> <li><mark>General hardware components:</mark>   The processor, the display, the sensors, and input devices, A typical smartphone contains a processor, a display accelerometer, GPS, camera, microphone, etc. and contains all the hardware required to be an AR device. However, there are quite challenges which we will discuss ahead.</li> <li><mark>Displays:</mark>   Apart from a typical monitor, which is perfectly capable of displaying AR data there, are other systems such as optical projection systems, head-mounted displays, virtual retinal displays etcetera.</li> <li><mark>Sensors and input devices:</mark>   GPS, gyroscopes, accelerometers, compasses, RFID, wireless sensors, touch recognition, speech recognition, eye tracking, and peripherals are the elements your devices need to have to be an AR device.</li> <li><mark>Software:</mark>   The majority of development for AR will be in developing further software to take advantage of the hardware capabilities. There is already an Augmented Reality Mark-up Language (ARML), which is being used to standardize XML grammar for virtual reality. Several software development kits (SDK) also offer simple environments for AR development. There is an open-sourced library focused on AR named ARTOOLKIT which can be used to build your own AR-based app. Google has also developed a platform for building augmented reality experiences for Android and iOS using ARCore and different available APIs.</li> </ul> <h3 id="applications-of-augmented-reality">Applications of Augmented Reality</h3> <p>There is a good chance that you are benefited from AR in your day-to-day life and it is nigh impossible that you haven’t come across AR in your lifetime. From camera filters to training future surgeons augmented reality is starting to infiltrate many industries of our society today.</p> <p>Looking at some most popular applications of AR, we have a location-based AR app, Google maps which plays digital direction on top of the real world and shows you where to walk.</p> <p>Another app from Google, which is based on AR, is Google Lens. It enhances the search experience. Herein you don’t have to type in your query anymore, instead just open the app and aim it at what you want to search. Google lens will identify the object and give you all the essential details about it.</p> <p>Next up is one of those parking assistants installed in your cars that you might have used. While reversing your car you can look at the screen for proper and accurate directions, using computer generated elements that gauge distances and trajectories in real time! As fascinating as it might seem, there’s a high chance this will be useless as self-driving and self-parking cars are all the rage now, nonetheless, these displays are an awesome piece of AR.</p> <p>Augmented Reality has also seeped into gaming and camera apps, and unless you’ve been living under a rock, you must’ve heard of Snapchat and Pokémon GO.</p> <p>Each year more and more AR and VR games and applications are added on the Playstore/Appstore, especially AR-based games, as they don’t require additional expensive hardware.</p> <h3 id="challenges-faced">Challenges faced</h3> <p>The progress in the domain of AR seems to be at an impasse because of the same challenges faced decades ago:</p> <ul> <li>High-end processor</li> <li>High-definition portable displays</li> <li>Portable power supplies A fully-fledged AR app can have your mobile’s battery exhausted in no time. And here we all are, already pestered by our smartphone’s battery not lasting long enough. So our smartphones don’t stand a chance to run these proficient AR-based apps.</li> </ul> <p>Similarly, a high-definition display which is portable too, is yet in progress. The displays of our smartphones have gotten significantly better with time but still don’t meet the needs. If we meet the criteria of a high-definition display, then we’ve to compromise on portability. The relation here goes as; portability is inversely proportional to the display quality.</p> <p>And lastly, the issue of processing or computing power of our devices. The mobile phones of today have greater computing power than the huge computers in old times. In this domain too, there have been remarkable improvements, but not enough to keep up with the complex AR and VR scenes as smoothly as a high processing gaming computer.</p> <h4 id="conclusion">Conclusion</h4> <p>Augmented reality has come a long way from a science-fiction concept to a science-based reality. AR has seen raging in popularity over the past few years and the revolution is not stopping any time soon. AR or augmented reality has gone from pipe dream to reality in just over a century. There are many AR applications in use or under development today, however - the concept will only take off universally when UX designers think about how they can integrate AR with daily life to improve productivity, efficiency, or quality of experiences. Moreover, to get the best out of AR, comprehensive development in multiple domains of technology is required to overcome the challenges we discussed above. There is unlimited potential for AR and the possibilities are endless, the big question is - how will it be unlocked?</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The Rise of Technology]]></summary></entry><entry><title type="html">Social Media</title><link href="https://mdarshad1000.github.io/blog/2022/social/" rel="alternate" type="text/html" title="Social Media"/><published>2022-01-17T21:01:00+00:00</published><updated>2022-01-17T21:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2022/social</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2022/social/"><![CDATA[<h2 id="social-media">Social Media</h2> <p><code class="language-plaintext highlighter-rouge">An Echo Chamber</code></p> <p><br/> If you want to bring a change, you need to go beyond having conversations with people who already agree with you. The majority who need to be addressed aren’t watching your Instagram stories. They don’t follow you on Twitter. Most of them aren’t even aware of the happenings. Start from within, and change the ones around you first before advocating to the general public.</p> <p>Social media is an echo chamber, meaning we seek out information that reinforces our existing views. Change does not happen inside an echo chamber. It’s time to have uncomfortable and direct conversations with the ones in question.</p> <p>Cutting yourself off from the people who do not agree with you from the jump is not the solution we seek. Your “wokeness” isn’t helpful if you’re only using it to shame people who aren’t informed. We have more to learn, we are all imperfect but growing.</p> <p>Holding everyone around you to some impossible standard of wokeness might make you feel smart but won’t create the change we’re hoping to see. Educate yourself and most importantly gather the information that opposes your point of view. Try to understand the “other side of the story”. Keep your ego aside, remove the blinkers restricting your vision, and then get going!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[An Echo Chamber]]></summary></entry><entry><title type="html">Disrupting Power Dynamics in the National Capital 🇮🇳</title><link href="https://mdarshad1000.github.io/blog/2021/gnctd/" rel="alternate" type="text/html" title="Disrupting Power Dynamics in the National Capital 🇮🇳"/><published>2021-05-05T21:01:00+00:00</published><updated>2021-05-05T21:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2021/gnctd</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2021/gnctd/"><![CDATA[<h2 id="disrupting-power-dynamics">Disrupting Power Dynamics</h2> <p><code class="language-plaintext highlighter-rouge">A Bleak Future for the National Capital</code></p> <p><br/></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/autocracy-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/autocracy-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/autocracy-1400.webp"/> <img src="/assets/img/autocracy.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Starting with what the NCT Amendment Bill 2021 is; it basically amends the Government of National Capital Territory of Delhi Act, 1991 to give primacy to the centrally appointed Lieutenant Governor of Delhi and make the elected Government of Delhi a subsidiary. The elected government will now have to seek the opinion of the Lieutenant Governor for any executive action. The GNCTD Amendment Act was enacted by the Government of India on 28 March 2021.</p> <p>The legislation amends a 1991 Act with regard to the powers and functions of the Delhi Government and the LG. It clearly defines the powers and functions of the Delhi government and the LG on the lines of the February 2019 judgment of the Supreme Court. This means it will give more power to the LG’s office.</p> <p>The latest amendment will greatly reduce the efficiency and timeliness of the Delhi government by making it imperative for it to hold consultations with the LG even when a situation demands urgent action, and given the recent happenings in the national capital during the infamous Delhi riots, or the Anti-CAA/NRC protests, the impotence of the Delhi Police, which is directly controlled by the Central government, was quite visible and all of this to pacify the right-wing politics of the BJP government. Furthermore to realize that this will worsen the working of the state government hence the situation of the state is saddening.</p> <p>This amendment in the act was least required as it doesn’t clearly state any logical reason for the same, the central government has tried enough to influence the multitude to focus on the non-existent virtues to shadow the pragmatic vices. We all are well aware of the tactics this government plays to suppress the actual issues of inflation, poverty, economic crises, declining law and order, inability to cope-up with the pandemic and the list goes on.</p> <p>For many, this can be a wise move by the Centre but de facto it’s a cowardly step to try and have control over the capital territory. The people who do support are the ones who are blindly following the biased politics which support their agenda. They portray themselves as “patriots” but in reality are a bunch of bigots who in reality are only loyal to the central government. However, the true patriots who love and care for the country are raising their voices against the unjust rule and such unconstitutional and futile decisions.</p> <p>Time and time we’ve seen the incompetence of this government, be it the blow of GST to our economy or the catastrophic demonetization which caused a nationwide ruckus. Government-backed media and huge money-fed propaganda machinery are trying to hide the fact that the government has failed on every single front by using the minority as scapegoats. This is a classic fascist government move but stupid and evil fall for it every time.</p> <blockquote> <p>Time to ask questions: is India an elected Autocracy?</p> </blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[Is India an elected Autocracy?]]></summary></entry><entry><title type="html">The Ever-Evolving Symphony of Science 🔭</title><link href="https://mdarshad1000.github.io/blog/2020/science/" rel="alternate" type="text/html" title="The Ever-Evolving Symphony of Science 🔭"/><published>2020-12-12T21:01:00+00:00</published><updated>2020-12-12T21:01:00+00:00</updated><id>https://mdarshad1000.github.io/blog/2020/science</id><content type="html" xml:base="https://mdarshad1000.github.io/blog/2020/science/"><![CDATA[<h2 id="the-ever-evolving-symphony-of-science">The Ever-Evolving Symphony of Science</h2> <p><code class="language-plaintext highlighter-rouge">How it has become the Heartbeat of Humanity</code></p> <p><br/></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/science-bg-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/science-bg-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/science-bg-1400.webp"/> <img src="/assets/img/science-bg.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Humankind being the supreme invention of mother nature has continuously been trying to know more, explore much, and do better by inventing and implementing something new. In the third decade of the twenty-first century it will be an understatement to say that science has changed our lives because science has become our way of life.</p> <p>Since the beginning of human civilization, science has changed human life tremendously. In the era of the stone and bronze age, man discovered metals and invented the wheels and started the journey of science and discovery. The essence of Islamic learning, changed the way of the world regarding the health, hygiene, and infrastructure which persuaded the west to relook at the Geek work of the likes of Pluto and Aristotle, changing the political philosophy and social makeup.</p> <p>Galileo’s discovery of Earth being round and revolving around the sun proved to be a real game changer. It compelled society to debate over the orthodox religious myths and science resulting in more science undoubtedly.</p> <p>The eighteenth and nineteenth century was certainly dominated by science, discovery, and inventions. The inception of steam engines and telegrams was a boon for human society. The distance seemed less and communication became much easier than man could have imagined. On a parallel track, biomedical science boomed and thereby opening up space for the treatment of diseases that were thought to be incurable. Discoveries in the field of computer science, physics, chemistry, and astronomy were at an all-time high resulting in the invention of Television and Computers on one hand and vaccines and robots on the other. Man saw the dark facet of science in the form of nuclear weapons and realized its worst fears but didn’t stop. </p> <p>Bit by bit man traveled to space and in no time he set foot on the moon. Going to the moon was no more a legend, it was the dumbfounding reality. The hunger to achieve more has made Mars his next destination.</p> <p>Concurrently, the World Wide Web brought the whole world together in just a click. Mobile communication and GPS enabled society to be where it actually couldn’t be. Artificial Intelligence took the field of computer science to new heights, what was earlier thought to be possible only by magic was now possible with the help of a few lines of code. Televisions brought a revolution in electronic media, possessing the power to make or break a government.</p> <p>In a hindsight, it’s quite terrifying yet fascinating to think of how life would’ve been without science. Science has become an integral part of everyone’s lives and it will continue to integrate further into our lives with every passing day.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[How it has become the Heartbeat of Humanity?]]></summary></entry></feed>