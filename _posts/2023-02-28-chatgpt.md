---
layout: post
title: ChatGPT
date: 2023-01-15 09:01:00
description: The subtle art of ChatGPT failure
tags: 
categories: 
---

### ChatGPT
`The subtle art of ChatGPT failure`


Is it an AGI? Is it SkyNet? No, it is a large language model. ChatGPT is a language model, optimised for dialogue and (for the first time?) equipped with a minimal, beautiful and responsive interface for interaction. There are warnings as soon as you start using it - it is in early stages, it can make mistakes, and it is NOT a lookup on the web(and yes it will not replace Google, at least not right now). 
I put it to a very specific task - to help me write the K-Nearest neighbours algorithm in PyTorch. It came to me because I had been thinking of putting myself to this task for a while. One of my friends had it as an interview question! So, here I was asking a Language model probably trained in PyTorch to give me PyTorch code for a simple KNN algorithm. It did not disappoint. It gave me a very neat looking code snippet, with very clear comments and the entire end to end algorithm - right from creating dummy synthetic data to finding the distances cleanly and then getting the predictions. I was very impressed! 

I started going through it in detail and there it lay. Very subtle. Extremely minute yet a very significant error. While inference, in order to find the top k nearest neighbours from the computed distances, GPT3 used the frequently employed topK PyTorch function. However, it did not set the argument to find the topK smallest numbers, instead it went by the default parameters which ended up fetching the topK largest distances! And voila, the final predictions were wrong. 

There is no way one would see this unless they are really looking into it. And that’s the problem - Trust. You can not trust the outputs from chat GPT to be the absolute truth. If someone were to have uploaded this answer on Stack Overflow, they would have had 10 downvotes, 3 comments, and a large case of imposter syndrome within the turn of the hour - and that is why humans probably still have the edge over trillions of weight parameters. TLDR-tread lightly with chat GPT if the output is even remotely significant to you! Or else, just play around and have fun!